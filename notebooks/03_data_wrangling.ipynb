{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5902e544",
   "metadata": {},
   "source": [
    "# SpaceX Data Wrangling & Feature Preparation\n",
    "\n",
    "## Objective\n",
    "Clean, standardize, and merge SpaceX launch data collected from\n",
    "the SpaceX API and Wikipedia into a unified dataset suitable for\n",
    "exploratory data analysis and machine learning.\n",
    "\n",
    "This step transforms raw, heterogeneous data sources into a\n",
    "consistent and analyzable format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d66be5a",
   "metadata": {},
   "source": [
    "## Input Datasets\n",
    "\n",
    "- **SpaceX API (raw)**: Launch metadata, rocket IDs, launch sites, outcomes\n",
    "- **Wikipedia (raw)**: Payload mass, orbit type, mission details\n",
    "\n",
    "Both datasets were persisted independently to ensure reproducibility\n",
    "and traceability across the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c464da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32f689ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((205, 43), (763, 10))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"../data/raw\")\n",
    "\n",
    "api_df = pd.read_csv(data_dir / \"spacex_launches_raw.csv\")\n",
    "wiki_df = pd.read_csv(data_dir / \"spacex_wikipedia_launches_raw.csv\")\n",
    "\n",
    "api_df.shape, wiki_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8894c65c",
   "metadata": {},
   "source": [
    "Before merging, both datasets require cleaning and normalization.\n",
    "Key challenges include:\n",
    "- Nested structures in API data\n",
    "- Non-numeric payload values\n",
    "- Inconsistent naming and missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8941d054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flight_number</th>\n",
       "      <th>name</th>\n",
       "      <th>date_utc</th>\n",
       "      <th>success</th>\n",
       "      <th>rocket</th>\n",
       "      <th>launchpad</th>\n",
       "      <th>payloads</th>\n",
       "      <th>cores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FalconSat</td>\n",
       "      <td>2006-03-24T22:30:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>5e9d0d95eda69955f709d1eb</td>\n",
       "      <td>5e9e4502f5090995de566f86</td>\n",
       "      <td>['5eb0e4b5b6c3bb0006eeb1e1']</td>\n",
       "      <td>[{'core': '5e9e289df35918033d3b2623', 'flight'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>DemoSat</td>\n",
       "      <td>2007-03-21T01:10:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>5e9d0d95eda69955f709d1eb</td>\n",
       "      <td>5e9e4502f5090995de566f86</td>\n",
       "      <td>['5eb0e4b6b6c3bb0006eeb1e2']</td>\n",
       "      <td>[{'core': '5e9e289ef35918416a3b2624', 'flight'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Trailblazer</td>\n",
       "      <td>2008-08-03T03:34:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>5e9d0d95eda69955f709d1eb</td>\n",
       "      <td>5e9e4502f5090995de566f86</td>\n",
       "      <td>['5eb0e4b6b6c3bb0006eeb1e3', '5eb0e4b6b6c3bb00...</td>\n",
       "      <td>[{'core': '5e9e289ef3591814873b2625', 'flight'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>RatSat</td>\n",
       "      <td>2008-09-28T23:15:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>5e9d0d95eda69955f709d1eb</td>\n",
       "      <td>5e9e4502f5090995de566f86</td>\n",
       "      <td>['5eb0e4b7b6c3bb0006eeb1e5']</td>\n",
       "      <td>[{'core': '5e9e289ef3591855dc3b2626', 'flight'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>RazakSat</td>\n",
       "      <td>2009-07-13T03:35:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>5e9d0d95eda69955f709d1eb</td>\n",
       "      <td>5e9e4502f5090995de566f86</td>\n",
       "      <td>['5eb0e4b7b6c3bb0006eeb1e6']</td>\n",
       "      <td>[{'core': '5e9e289ef359184f103b2627', 'flight'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flight_number         name                  date_utc success  \\\n",
       "0              1    FalconSat  2006-03-24T22:30:00.000Z   False   \n",
       "1              2      DemoSat  2007-03-21T01:10:00.000Z   False   \n",
       "2              3  Trailblazer  2008-08-03T03:34:00.000Z   False   \n",
       "3              4       RatSat  2008-09-28T23:15:00.000Z    True   \n",
       "4              5     RazakSat  2009-07-13T03:35:00.000Z    True   \n",
       "\n",
       "                     rocket                 launchpad  \\\n",
       "0  5e9d0d95eda69955f709d1eb  5e9e4502f5090995de566f86   \n",
       "1  5e9d0d95eda69955f709d1eb  5e9e4502f5090995de566f86   \n",
       "2  5e9d0d95eda69955f709d1eb  5e9e4502f5090995de566f86   \n",
       "3  5e9d0d95eda69955f709d1eb  5e9e4502f5090995de566f86   \n",
       "4  5e9d0d95eda69955f709d1eb  5e9e4502f5090995de566f86   \n",
       "\n",
       "                                            payloads  \\\n",
       "0                       ['5eb0e4b5b6c3bb0006eeb1e1']   \n",
       "1                       ['5eb0e4b6b6c3bb0006eeb1e2']   \n",
       "2  ['5eb0e4b6b6c3bb0006eeb1e3', '5eb0e4b6b6c3bb00...   \n",
       "3                       ['5eb0e4b7b6c3bb0006eeb1e5']   \n",
       "4                       ['5eb0e4b7b6c3bb0006eeb1e6']   \n",
       "\n",
       "                                               cores  \n",
       "0  [{'core': '5e9e289df35918033d3b2623', 'flight'...  \n",
       "1  [{'core': '5e9e289ef35918416a3b2624', 'flight'...  \n",
       "2  [{'core': '5e9e289ef3591814873b2625', 'flight'...  \n",
       "3  [{'core': '5e9e289ef3591855dc3b2626', 'flight'...  \n",
       "4  [{'core': '5e9e289ef359184f103b2627', 'flight'...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_cols = [\n",
    "    \"flight_number\",\n",
    "    \"name\",\n",
    "    \"date_utc\",\n",
    "    \"success\",\n",
    "    \"rocket\",\n",
    "    \"launchpad\",\n",
    "    \"payloads\",\n",
    "    \"cores\"\n",
    "]\n",
    "\n",
    "api_df = api_df[api_cols]\n",
    "api_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e231f6",
   "metadata": {},
   "source": [
    "## Cleaning Payload Mass\n",
    "\n",
    "Payload mass values extracted from Wikipedia often contain\n",
    "units, annotations, or missing values.\n",
    "These values must be converted into numeric kilograms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1d8335f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['payload[k]', 'payload_mass']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload_candidates = [\n",
    "    col for col in wiki_df.columns\n",
    "    if \"payload\" in col.lower()\n",
    "]\n",
    "\n",
    "payload_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b9c7df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'payload[k]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload_col = payload_candidates[0]\n",
    "payload_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7c6b441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     725.000000\n",
       "mean       95.707172\n",
       "std       367.055309\n",
       "min         0.000000\n",
       "25%         6.000000\n",
       "50%        15.000000\n",
       "75%        26.000000\n",
       "max      4000.000000\n",
       "Name: payload[k], dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df[payload_col] = (\n",
    "    wiki_df[payload_col]\n",
    "    .astype(str)\n",
    "    .str.replace(\",\", \"\", regex=False)\n",
    "    .str.extract(r\"(\\d+\\.?\\d*)\")[0]\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "wiki_df[payload_col].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f67e41",
   "metadata": {},
   "source": [
    "## Column Normalization\n",
    "\n",
    "Column names are standardized to ensure consistency\n",
    "across datasets prior to merging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b73cc9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['flight_no.', 'date_and_time_(utc)', 'version,_booster[j]',\n",
       "       'launch_site', 'payload_mass_kg', 'payload_mass', 'orbit', 'customer',\n",
       "       'launch_outcome', 'booster_landing'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df = wiki_df.rename(columns={\n",
    "    payload_col: \"payload_mass_kg\",\n",
    "    \"orbit\": \"orbit\"\n",
    "})\n",
    "\n",
    "wiki_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e542321e",
   "metadata": {},
   "source": [
    "## Creating Landing Outcome Label\n",
    "\n",
    "For downstream analysis, a binary target variable is created:\n",
    "- `1` → Successful landing\n",
    "- `0` → Failed landing\n",
    "\n",
    "This label will be used in both EDA and machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e5b4a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f4/1bx7ntl12p3_b33_lgfy2_t40000gn/T/ipykernel_49750/3753731711.py:1: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  api_df[\"landing_success\"] = api_df[\"success\"].fillna(False).astype(int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "landing_success\n",
       "1    181\n",
       "0     24\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_df[\"landing_success\"] = api_df[\"success\"].fillna(False).astype(int)\n",
    "\n",
    "api_df[\"landing_success\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6829d0",
   "metadata": {},
   "source": [
    "## Data Integration Strategy\n",
    "\n",
    "Although both the SpaceX API and Wikipedia contain launch-related\n",
    "information, they do not share a reliable common identifier that\n",
    "allows consistent record-level merging.\n",
    "\n",
    "Differences in flight numbering conventions, mission naming,\n",
    "and editorial formatting prevent a robust one-to-one join.\n",
    "\n",
    "For this project:\n",
    "- The SpaceX API is used as the primary analytical dataset for\n",
    "  exploratory analysis, dashboards, and machine learning.\n",
    "- Wikipedia data is treated as a complementary source to analyze\n",
    "  payload mass distributions, orbit types, and qualitative outcomes.\n",
    "\n",
    "This approach avoids forcing unreliable joins and reflects\n",
    "best practices when working with heterogeneous real-world data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d963874d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f4/1bx7ntl12p3_b33_lgfy2_t40000gn/T/ipykernel_49750/4231516662.py:6: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .fillna(False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(205, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select and clean API dataset (main analytical dataset)\n",
    "api_clean = api_df.copy()\n",
    "\n",
    "api_clean[\"landing_success\"] = (\n",
    "    api_clean[\"success\"]\n",
    "    .fillna(False)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "api_clean[\"launch_date\"] = pd.to_datetime(api_clean[\"date_utc\"]).dt.date\n",
    "\n",
    "api_clean = api_clean.dropna(subset=[\"launch_date\"])\n",
    "\n",
    "api_clean.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d81d33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(763, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_clean = wiki_df.copy()\n",
    "\n",
    "# Clean Wikipedia date field (remove reference annotations like [23])\n",
    "wiki_clean[\"launch_date\"] = (\n",
    "    wiki_clean[\"date_and_time_(utc)\"]\n",
    "    .astype(str)\n",
    "    .str.replace(r\"\\[.*?\\]\", \"\", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "wiki_clean[\"launch_date\"] = pd.to_datetime(\n",
    "    wiki_clean[\"launch_date\"],\n",
    "    errors=\"coerce\"\n",
    ").dt.date\n",
    "\n",
    "wiki_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c774dc5f",
   "metadata": {},
   "source": [
    "## Final Datasets\n",
    "\n",
    "Due to the lack of a reliable one-to-one identifier between the SpaceX API\n",
    "and Wikipedia sources, the final data pipeline produces **two clean and\n",
    "independent datasets**, each optimized for a specific analytical purpose.\n",
    "\n",
    "### 1. SpaceX API Dataset (Primary)\n",
    "\n",
    "This dataset is derived from the official SpaceX API and serves as the\n",
    "**primary analytical dataset** for the project.\n",
    "\n",
    "It contains:\n",
    "- Launch metadata (date, rocket, launch site)\n",
    "- Core and payload configuration\n",
    "- Binary landing success label (`landing_success`)\n",
    "- Structured fields suitable for modeling and visualization\n",
    "\n",
    "This dataset is used for:\n",
    "- Exploratory data analysis\n",
    "- Interactive dashboards (Plotly Dash)\n",
    "- Machine learning classification models\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Wikipedia Dataset (Complementary)\n",
    "\n",
    "This dataset is derived from Wikipedia launch tables and provides\n",
    "**complementary mission-level insights**.\n",
    "\n",
    "It contains:\n",
    "- Payload mass (kg)\n",
    "- Orbit type\n",
    "- Customer information\n",
    "- Qualitative launch and landing outcomes\n",
    "\n",
    "This dataset is used for:\n",
    "- Payload and orbit distribution analysis\n",
    "- Cross-validation of trends observed in API data\n",
    "- Descriptive and contextual visualizations\n",
    "\n",
    "---\n",
    "\n",
    "### Design Decision\n",
    "\n",
    "Separating the datasets avoids forcing unreliable joins and reflects\n",
    "best practices when working with heterogeneous real-world data sources.\n",
    "This approach ensures data integrity while preserving analytical value\n",
    "from both sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ed79ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"../data/processed\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "api_clean.to_csv(output_dir / \"spacex_api_clean.csv\", index=False)\n",
    "wiki_clean.to_csv(output_dir / \"spacex_wikipedia_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4916cb",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "The cleaned dataset will be used to perform:\n",
    "- Exploratory data analysis using visualization and SQL\n",
    "- Interactive analytics using Plotly and Dash\n",
    "- Machine learning classification models\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacex-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
